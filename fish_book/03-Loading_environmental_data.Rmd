## Load environmental data

### Load land data and shapefiles of different regions

Load land data

```{r landread, echo=TRUE}
land<-rgdal::readOGR(dsn=file.path(fish.path,"Environmental_variables/shapefiles/WGS84/"),layer="WGS84geoKust500")
projection(land)<-CRS("+proj=longlat +datum=WGS84")
land.utm<-land
land.utm <- spTransform(land,CRS(common.projection))
```

Load Different regions

```{r region_read, echo=TRUE, dpi=300, fig.width=8, fig.height=8}
ICES<-rgdal::readOGR(dsn=file.path(fish.path,"Environmental_variables/shapefiles/ICES_gebieden_V7_WGS84/"),layer="ICES_gebieden_V7_WGS84")
ICES.utm<-ICES
ICES.utm <- spTransform(ICES,common.projection)
load(file=file.path(fish.path,"Environmental_variables/shapefiles/SHAPES.RDATA"))

ICES.utm.buffer           <- gBuffer(ICES.utm, F, width = 10000) # Sander used 20000

proj4string(BB)<-"+proj=longlat +ellps=WGS84"
BB  <- spTransform(BB, common.projection)

proj4string(VD)<-"+proj=longlat +ellps=WGS84"
VD  <- spTransform(VD, common.projection)

proj4string(VD.trans3)<-"+proj=longlat +ellps=WGS84"
VD.trans3  <- spTransform(VD.trans3, common.projection)

load(file=file.path(fish.path,"Environmental_variables/shapefiles/eurPols.Rdata"))

BBVD<-rgdal::readOGR(dsn=file.path(fish.path,"Environmental_variables/shapefiles/Bodembeschermingsgebied Voordelta/"),layer="DNZ_bodembeschermingsgebied")
projection(BBVD)
BBVD  <- spTransform(BBVD, common.projection)

plot(VD.trans3,border="darkgreen",lwd=2)
plot(land.utm,add=TRUE,col="beige")
plot(VD,add=TRUE,border="green",lwd=2)
plot(BB,add=TRUE,border="red",lwd=3)
plot(BBVD,add=TRUE,border="orange",lty=3,lwd=2)
plot(ICES.utm,add=TRUE,lty=2)
plot(ICES.utm.buffer,add=TRUE,lty=3)
box(lwd=2)


```

Data is overlayed with some shapefiles. This is e.g. needed for extracting the VMS data and differentating between NA and 0. 

```{r shape_overlay, echo=TRUE, cache=TRUE, eval=T}

      coordinates(dat)<-~x_utm + y_utm
      projection(dat)<-CRS(common.projection)
      
      id<-over(dat,ICES.utm)
      dat$in_ICES<-is.na(id$Area_code)==FALSE
      id<-over(dat,ICES.utm.buffer)
      dat$in_ICES_buffer<-is.na(id)==FALSE
      id<-over(dat,BB)
      dat$in_BB<-is.na(id$Id)==FALSE

```



### Load depth data

Next we load and process the depth data. We only run it once, to save time. Only depth data is selected within the range of the DFS survey data.

```{r depthread, echo=TRUE, cache=TRUE, eval=TRUE}

# 
if (is.element("depth_raster.rdata",dir(file.path(env.path,"depth/Europe/Emodnet_DTM2018/")))){
  load(file.path(env.path,"depth/Europe/Emodnet_DTM2018/depth_raster.rdata"))}

if (is.element("depth_raster.rdata",dir(file.path(env.path,"depth/Europe/Emodnet_DTM2018/")))==FALSE){
  
  # What is the cellsize?
  val<-raster(file.path(env.path,"depth/europe/Emodnet_DTM2018/C4_2018.asc"))
  cellsize<-(val@extent@xmax-val@extent@xmin)/val@ncols
  print(cellsize)
  dist.x<-distm(c(5, 53), c(5+cellsize, 53))
  print(dist.x)
  dist.y<-distm(c(5, 53), c(5, 53+cellsize))
  print(dist.y)
  grid.size<-min(c(dist.x,dist.y))
  grid.size<-500
  
  # Create regular grid based on extremes of fish data
  xy<-expand.grid(x=seq(from=min(dat$x_utm), to=max(dat$x_utm),by=grid.size),
                  y=seq(from=min(dat$y_utm), to=max(dat$y_utm),by=grid.size))
  xy$lon<-xy$x; xy$lat<-xy$y
  coordinates(xy) <- c("lon", "lat")
  proj4string(xy) <- CRS("+init=epsg:32631")
  xy <- as.data.frame(spTransform(xy, CRS("+proj=longlat +datum=WGS84")))
  
  # Extract values  
  tiles<-c("E4","E5","D4","D5","C4","C5")
  for (i in tiles){
    print(i)
    val<-raster(paste(env.path,"/depth/europe/Emodnet_DTM2018/",i,"_2018.asc",sep=""))
    xy[,i]<-extract(val, xy[,c('lon','lat')])
  }
  
  # Calculate means of depth  
  xy$depth<-rowMeans(xy[,c("E4","E5","D4","D5","C4","C5")],na.rm=TRUE)
  summary(xy$depth)
  xy<-xy[,-na.omit(match(c("E4","E5","D4","D5","C4","C5"),names(xy)))]
  xy<-xy[,c("x","y","depth")]
  
  # Create raster
  M<-matrix(xy$depth,nrow=length(unique(xy$x)),ncol=length(unique(xy$y)))
  M<-t(M)
  M<-M[nrow(M):1,]
  M.raster<-raster(M,xmn=min(xy$x), xmx=max(xy$x), ymn=min(xy$y), ymx=max(xy$y))
  
  # Write.table
  save(M.raster,file=file.path(env.path,"depth/europe/Emodnet_DTM2018/depth_raster.rdata"))
  
}

```

And plot the depth data

```{r depth_plot, echo=TRUE, eval=T, dpi=300, fig.width=6, fig.height=6}
plot(M.raster)
plot(land.utm,add=TRUE,border="grey75",col="grey90")
box(lwd=2)  
```

Calculate topographic index and plot. Note that you will get no data values at the edges. One way to prevent this could be to calculate the TPI for different scales (e.g. 1, 3, etc.) and use a smaller scale value when missing for the larger scale (e.g. 15)

```{r tpi, echo=TRUE, eval=T, dpi=300, fig.width=6, fig.height=6}
  tpi_depth3<-tpi(M.raster, scale = 3, win = "rectangle", normalize = FALSE)
  tpi_depth9<-tpi(M.raster, scale = 9, win = "rectangle", normalize = FALSE)
  tpi_depth15<-tpi(M.raster, scale = 15, win = "rectangle", normalize = FALSE)
  
  plot(tpi_depth15)
  plot(land.utm,add=TRUE,border="grey75",col="grey90")
  box(lwd=2)  
```

### Load sediment data

Here we load and plot the Sediment data. These data are from 2007. 

```{r sediment_read, echo=TRUE, cache=TRUE, eval=T, dpi=300, fig.width=8, fig.height=8}

# Create regular grid based on extremes of fish data
par(mfrow=c(2,2),mai=c(0.1,0.1,0.2,0.2)) 
  slibNL<-raster(file.path(env.path,"sediment/NL/ascii/slib_juli2007.asc"))
    projection(slibNL)<-CRS(common.projection)
    plot(slibNL,xaxt="n",yaxt="n",main="slib")
    plot(land.utm,add=TRUE,border="grey75",col="grey90")
    box()
    
    zand<-raster(file.path(env.path,"sediment/NL/ascii/zand_afgeleid.asc"))
    projection(zand)<-CRS(common.projection)
    plot(zand,xaxt="n",yaxt="n",main="zand")
    plot(land.utm,add=TRUE,border="grey75",col="grey90")
    box()
    
    dz10<-raster(file.path(env.path,"sediment/NL/ascii/dz10_juli2007.asc"))
    projection(dz10)<-CRS(common.projection)
    plot(dz10,xaxt="n",yaxt="n",main="dz10")
    plot(land.utm,add=TRUE,border="grey75",col="grey90")
    box()
    
    dz60<-raster(file.path(env.path,"sediment/NL/ascii/dz60_juli2007.asc"))
    projection(dz60)<-CRS(common.projection)
    plot(dz60,xaxt="n",yaxt="n",main="dz60")
    plot(land.utm,add=TRUE,border="grey75",col="grey90")
    box()
    
```



### Load fisheries data

Here we load and plot the Sediment data. These data are from 2007. 

```{r VMS_data, echo=TRUE, cache=TRUE, eval=T}

load(file.path(PMR.data.path,"VMS/grd_2014.Rdata"))
#proj4string(grd)
plot(VD.trans3,border="darkgreen",lwd=2)
plot(dat,add=TRUE)
plot(land.utm,col="beige",add=TRUE)

#definieer titel

iG=unlist(strsplit(names(grd)[79],"_"))[1]
if(iG == 'Gar')    ititel <- 'garnalen'
if(iG == 'BkorG')  ititel <- 'boomkorGroot'
if(iG == 'Pkor')   ititel <- 'puls'
if(iG == 'Bkor')   ititel <- 'boomkor'
if(iG == 'Bor')    ititel <- 'borden'
if(iG == 'Dreg')   ititel <- 'dreggen'
if(iG == 'Anders') ititel <- 'overige'

#plot(grd[7],add=TRUE,main=ititel)
#plot(grd[78],add=TRUE,main=ititel)

empty.mat<-as.data.frame(matrix(NA,nrow=nrow(dat),ncol=length(names(grd))))
names(empty.mat)<-names(grd)

the.years<-c(2004:2018)

for (the.year in the.years){

print(the.year)
  
load(file.path(PMR.data.path,paste("VMS/grd_",the.year,".Rdata",sep="")))

covariates<- dat[dat$year==the.year,] %over% grd
covariates[is.na(covariates)]<-0


empty.mat[dat$year==the.year,names(covariates)]<-covariates

}
empty.mat[is.na(empty.mat)]<-0
empty.mat[dat$in_ICES_buffer==FALSE,]<-NA

empty.mat$Gar_8_9<-empty.mat$Gar_surf_8+empty.mat$Gar_surf_9
empty.mat$Pkor_8_9<-empty.mat$Pkor_surf_8+empty.mat$Pkor_surf_9
empty.mat$Bkor_8_9<-empty.mat$Bkor_surf_8+empty.mat$Bkor_surf_9



dat<-cbind(as.data.frame(dat),as.data.frame(empty.mat[,c("Gar_8_9","Pkor_8_9","Bkor_8_9")]))

# Check w

```


## Link survey data with environmental data

Below the model data is linked to the explanatory variables.

```{r extract, echo=TRUE, eval=T}
      dat$slib <-extract(slibNL, dat[,c('x_utm','y_utm')])
      dat$zand <-extract(zand, dat[,c('x_utm','y_utm')])
      dat$dz10 <-extract(dz10, dat[,c('x_utm','y_utm')])
      dat$dz60 <-extract(dz60, dat[,c('x_utm','y_utm')])
      dat$tpi_3 <-extract(tpi_depth3, dat[,c('x_utm','y_utm')])
      dat$tpi_9 <-extract(tpi_depth9, dat[,c('x_utm','y_utm')])
      dat$tpi_15 <-extract(tpi_depth15, dat[,c('x_utm','y_utm')])
      dat$depth <-extract(M.raster, dat[,c('x_utm','y_utm')])
```

For some data points the values for the environmental variables are missing. For "depth" we can simply use "water_depth" as measured during the survey. To check whether this is correct, we make a plot between these two.

```{r water_depth_vs_depth, echo=TRUE, cache=TRUE, eval=T, dpi=300, fig.width=4, fig.height=4}

plot(-dat$water_depth,dat$depth)    
```
For sediment, data is missing for the Wadden Sea and some part of the Delta area. To still allow the data to be used in the model, we create a new variable which indicates whether the sampling locations is located within the missing-data area, and we set the values for the sediment variables to 0. 

```{r missing_1, echo=TRUE, eval=T}
      dat$missing<-0
      dat$missing[is.na(dat$slib)]<-1
      dat$slib[is.na(dat$slib)]<-0
      dat$zand[is.na(dat$zand)]<-0
      dat$dz10[is.na(dat$dz10)]<-0
      dat$dz60[is.na(dat$dz60)]<-0
   
```
For the topographic position index it is set to tpi values of finer spatial scales when missing. E.g. When there is no data for tpi 15cells, we will use tpi of 9 cells. For the finest scale (i.e. tpi 3cells) we set it to the mean tpi value. This could be improved
 
```{r missing_2, echo=TRUE, eval=T}
      dat$missing<-0
       dat$tpi_3[is.na(dat$tpi_3)]<-mean(dat$tpi_3,na.rm=TRUE)
      dat$tpi_9[is.na(dat$tpi_9)] <-dat$tpi_3[is.na(dat$tpi_9)]
      dat$tpi_15[is.na(dat$tpi_15)] <-dat$tpi_9[is.na(dat$tpi_15)]
      summary(dat)
```

### Load NET cdf files

The .nc files are stored on the server. It appears that it is not possible to make a direct link with these .nc files, but it seems necessary to download these files first. The code below downloads all the files from the server. Only the files are selected where abiotiek$use0 == 1 in the abiotic_variable files.

```{r download_NC, echo=TRUE, eval=T}

# Load library
  library(RCurl)

# Define local path to store files
  local.nc.path<-"D:/Deltares_NetCDF/"

# Read file which specifies which files to read  
  abiotiek<-read.csv(file.path(PMR.data.path,"Deltares/Abiotic_variables.csv"))

# Loop through all the years  
for (the.year in 2005:2018){
  
  # Show the year
    print(the.year)

  # Thefine the url location
    url<- paste("http://pmr-geoserver.deltares.nl/thredds/fileServer/PMR-NCV/abiotiek/",the.year,"/",sep="")

  # Define the files to read  
    TF<-(abiotiek$use0==1)
    files<-paste(abiotiek$parameter[TF],abiotiek$period[TF],
                 abiotiek$layer10[TF],abiotiek$aggregation[TF],"_",
                 the.year,abiotiek$veld[TF],".nc",sep="")
    
  # Loop through all the files  
    for(i in seq_along(files)){
      if (is.element(files[i],dir(local.nc.path))==FALSE)
      try(download.file(paste(url,files[i],sep=""),
                        destfile=file.path(local.nc.path,files[i]),quiet=FALSE,
                        mode="wb", cacheOK = TRUE))}
    
}
```

More information on how to extract nc files, can be found here:
http://geog.uoregon.edu/bartlein/courses/geog490/week04-netCDF.html#reading-a-netcdf-data-set-using-the-ncdf4-package
  
  
```{r extract_NETcdf, echo=TRUE, eval=T, dpi=300, fig.width=7, fig.height=7}

# The extraction is only ran for all years of the trawl data with environmental data is not existing
  the.years<-ifelse(is.element("dfs4pmr_trllst_ENV.csv", dir(file.path(PMR.data.path,"DFS"))),2005,2005:2018)

# Add columns to dat
  the.rows<-which(abiotiek$use0==1)
  the.year="xxxx"
  the.col.names<-paste(abiotiek$parameter,abiotiek$period,
                       abiotiek$layer10,abiotiek$aggregation,"_",the.year,abiotiek$veld,".nc",sep="")[the.rows]

# Create empty matrix to store results  
  empty.dat<-as.data.frame(matrix(NA,nrow=nrow(dat),ncol=length(the.col.names)*2))
  names(empty.dat)<-c(the.col.names,paste(the.col.names,"7d",sep="_"))

# Combine with trawl data  
  dat<-cbind(dat,empty.dat)
  
# Extract files 
#for (the.year in 2005:2018)
for (the.year in the.years)
{
  
  # Define the files for that year
    files<-paste(abiotiek$parameter,abiotiek$period,
                 abiotiek$layer10,abiotiek$aggregation,"_",the.year,abiotiek$veld,".nc",sep="")[the.rows]
  
  # Select data from year
    dat.y<-dat[dat$year==the.year,]  

  # Loop through all the files
    for (j in 1:length(files)){
    #for (j in 1:10){
      
    # Define the file and column name
      print(file<-files[j])
      the.col.name<-the.col.names[j]
      the.col.name.7d<-paste(the.col.name,"7d",sep="_")
      
    # Only run if files exist
      if (is.element(file,dir(local.nc.path))){
  
    # open a NetCDF file
      ncin <- nc_open(file.path(local.nc.path,file))
      #print(ncin)
    
    # Get longitude and latitue  
      lon <- ncvar_get(ncin,"lon")
      nlon <- dim(lon)
      #unique(na.omit(c(lon)))
  
      lat <- ncvar_get(ncin,"lat")
      nlat <- dim(lat)
      #unique(na.omit(c(lat)))
  
    # Transform to utm coordinates  
      xy<-data.frame(lon=c(lon),lat=c(lat))
      xy$id<-1:nrow(xy) #important to have this year, before na remove
      No.NAs<-which(is.na(xy$lon)==FALSE & is.na(xy$lat)==FALSE)
      xy<-xy[No.NAs,]
      xy$x_utm<-xy$lon; xy$y_utm<-xy$lat
      coordinates(xy)<-~x_utm + y_utm
      projection(xy)<-CRS("+proj=longlat +datum=WGS84")
      xy <- as.data.frame(spTransform(xy,CRS(common.projection)))
      
    # fast nearest neighbour search
      closest <- nn2(xy[,c("x_utm","y_utm")],cbind(dat.y$x_utm,dat.y$y_utm),k = 1, searchtype = "radius", 
                     radius = 5000)
      closest$nn.idx[closest$nn.idx==0]<-NA
      dat.y$layer.idx<-xy$id[closest$nn.idx]
      dat.y$layer.dist<-closest$nn.dists
      
    # get time
      time <- ncvar_get(ncin,"time")
      ncatt_get(ncin,"time","units") # should be days since start of year
 
    # get variable of interest
      dname=names(ncin$var)[6]
      tmp_array <- ncvar_get(ncin,dname)
      
    # replace netCDF fill values with NA's
      fillvalue <- ncatt_get(ncin,dname,"_FillValue")
      tmp_array[tmp_array==fillvalue$value] <- NA
  
    # Do extraction for all values if there is only one map/layer
      if (length(dim(tmp_array))==2) {
        # Get value
          dat[dat$year==the.year,][,the.col.name]<-c(tmp_array)[dat.y$layer.idx]
      
        # Make plot (only once) 
          if (the.year==2005) {
          kleur<-c(as.numeric(tmp_array))[No.NAs]
          kleur<-rainbow(120)[round(100*(kleur-min(kleur,na.rm=TRUE))/(diff(range(kleur,na.rm=TRUE))))+1]
          coordinates(xy)<-~lon + lat
          plot(xy,col=kleur,pch=20,cex=0.5,main=file)
          plot(land,add=TRUE)
           }}

    # Do extraction by time if there are muliple layers
      if (length(dim(tmp_array))==3) {
 
    # Loop through all rows of trawl data  
    for (i in 1:nrow(dat.y))
    {
       # Calculate time difference
         tdif<-dat.y$day_of_year[i]-(time-1/24) # time = 0 is at UTC+1 (NL wintertime), 
                                                # day_of_year is at UTC, 
                                                # so substraction of 1 hour from time, results in UTC
         nearest_layer<-which.min(abs(tdif))[1]
         
         tdif<-(dat.y$day_of_year[i]-7)-(time-1/24) # 7 days earlier
         nearest_layer_7days<-which.min(abs(tdif))[1]
     
     # Select relevant slices
       m <- nearest_layer
       m.7<-max(1,nearest_layer_7days)
       tmp_slice <- tmp_array[,,m.7:m]

     # Function to get rowMeans if multidimensional array       
       means.along <- function(a, i) {
         n <- length(dim(a))
         b <- aperm(a, c(seq_len(n)[-i], i))
         rowMeans(b, dims = n - 1, na.rm=TRUE)
       }
       
     # Calculate mean over all slices   
       tmp_slice<-means.along(tmp_slice,3)
     
     # Make plot (only once) 
       if (the.year==2005 & i==1) {
          kleur<-c(as.numeric(tmp_slice))[No.NAs]
          kleur<-rainbow(120)[round(100*(kleur-min(kleur,na.rm=TRUE))/(diff(range(kleur,na.rm=TRUE))))+1]
          coordinates(xy)<-~lon + lat
          plot(xy,col=kleur,pch=20,cex=0.5,main=file)
          plot(land,add=TRUE)
          }
          

     # Get value   
       dat[dat$year==the.year,][i,the.col.name.7d]<-c(tmp_slice)[dat.y$layer.idx[i]]
      
     # Get value at moment of survey
       tmp_slice <- tmp_array[,,m]
       dat[dat$year==the.year,][i,the.col.name]<-c(tmp_slice)[dat.y$layer.idx[i]]
     
       }
    }
  }
    }
}
```

Finally the table is saved

```{r write_trawl_list, echo=TRUE, eval=T}

if (length(the.years)>1)  write.csv(dat,file.path(PMR.data.path,"DFS/dfs4pmr_trllst_ENV.csv"))   

```