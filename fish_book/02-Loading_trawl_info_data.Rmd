#Data preparation

##Load and prepare survey data

There are two file types; 
- Trawl table, defining where, when and how trawling took place
- Catch data, defining which species (and size) were caught

The trawl list table is the one to be linked to environmental data, and can later be linked to the catch data.

First the necessary file location 'paths' are specified.  

```{r, echo=TRUE}
if (Sys.info()["nodename"]=="L0151542") {path<-"c:/github/CoastalFish/fish_book/data";
env.path<-"C:/Users/aarts012/Dropbox/Seal_database/environmental";
PMR.data.path<-"W:/IMARES/Data/PMR/PMR 2019/Perceel Vis/3. data/"}
```

Libraries are loaded

```{r, echo=TRUE, warning=FALSE, message=FALSE}
library(INLA); library(fields); 
library(mgcv)
library(lattice); library(latticeExtra); library(grid); library(gridExtra);
library(rgdal); library(rgeos); 
library(mapdata); library(maptools);
library(raster);library(geosphere);
library(spatialEco); library(rgeos); 
library(RColorBrewer);library(GISTools)
#library(vmstools); 
library(GISTools) ;library(ncdf4); 
library(RANN); library(plyr)

```

Next we load the trawl data and standardize it in a way that it can be used by a more the standardized R INLA protocol.

```{r trawlload, echo=TRUE}
dat<-read.csv(file.path(PMR.data.path,"DFS/dfs4pmr_trllst2.csv"))
names(dat)<-tolower(names(dat))
```

In the table there should be a code with a unique id for each haul. So we check whether there are any dupplications

```{r, echo=TRUE}
dat$id <- paste(dat$year, dat$sample, sep="-")  ## different years share the same "sample" code
sum(duplicated(dat$id))
```


A column for the date and time is created based on separate columns

```{r time_process_trawl, echo=TRUE}
# Get date and time
  dat$time<-sprintf("%04d", dat$time)
  dat$date_time<-paste(dat$year,"-", dat$month,"-",dat$day," ", dat$time, sep="")
  dat$ddate<-as.POSIXct(strptime(dat$date_time,format="%Y-%m-%d %H%M",tz="UTC")) 
  tail(dat[,c("date_time","ddate")])

# Get day of year
  dat$day_of_year<-as.numeric(difftime(dat$ddate,as.POSIXct(strptime(paste(dat$year,"-01-01 0000", sep=""),format="%Y-%m-%d %H%M",tz="UTC"),units="days")))

# Rename latitude and longitude
  dat$lon<-dat$longitude_s
  dat$lat<-dat$latitude_s

# Only select columns with data  
  nrow(dat)
  dat<-dat[is.na(dat$lat)==FALSE & is.na(dat$lon)==FALSE,]
  nrow(dat)
  
# Only use data from 2014 until 2018
  dat<-dat[dat$year>=2005 & dat$year<=2018,]
```

We now remove all unnecessary columns 

```{r, echo=TRUE}
dat<-dat[,c("id","ddate","year","day_of_year","lon","lat","pmr_area_code","water_depth","wind_direction","wind_force","temperature_s","valid","duration","bottom_track","tor_code","modelledtidalphase")]
```

All necessary columns are given a standard name, and utm coordinates are calculated. All rows with no lat or lon coordinates are removed. 

```{r process_trawl, echo=TRUE}

# Define common projection
  common.projection<-"+proj=utm +zone=31 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs84=0,0,0"
  # Same as +init=epsg:32631

# Get utm coordinates  
  xy<-project(cbind(dat$lon,dat$lat), common.projection)
  dat$x_utm<-xy[,1]
  dat$y_utm<-xy[,2]
 
# Show data   
  str(dat)
``` 



```{r create regular grid, echo=TRUE, dpi=300, fig.width=6, fig.height=6}

# Create buffer around trawl locations
  coordinates(dat)<-~x_utm + y_utm
  dat.buffer<- gBuffer(dat, F, width = 10000) 
  #plot(dat.buffer)

# Create regular grid  
  xy<-expand.grid(x_utm=seq(from=min(dat$x_utm),to=max(dat$x_utm),by=2000),
                  y_utm=seq(from=min(dat$y_utm),to=max(dat$y_utm),by=2000))
  coordinates(xy)<-~x_utm + y_utm
  
# Only use regular grid points within buffer    
  xy$within<-over(xy, dat.buffer , fn = NULL) 
  xy<-xy[is.na(xy$within)==FALSE,]
  #plot(xy,add=TRUE,col="grey")

# Get latlon
  latlon<-xy
  proj4string(latlon)<-common.projection
  latlon<-as.data.frame(coordinates(spTransform(latlon,CRS("+proj=longlat +ellps=WGS84"))))
  names(latlon)<-c("lon","lat")
  
# Combine with xy
  xy<-cbind(as.data.frame(xy),latlon)
  
# Get id, ddate, year and day_of_year
  xy$year<-2017
  xy$ddate<-median(dat$ddate[dat$year==2017])
  xy$day_of_year<-median(dat$day_of_year[dat$year==2017])
  xy$id<-"2017_predict"
  
# Combine regular grid with trawl data  
  dat<-rbind.fill(as.data.frame(dat),xy)
  
``` 

